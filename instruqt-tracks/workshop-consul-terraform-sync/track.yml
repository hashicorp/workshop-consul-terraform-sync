slug: workshop-consul-terraform-sync
id: zd9iqr8wyub0
version: 0.0.1
type: track
title: Workshop consul-terraform-sync
teaser: Use Terraform and Consul to manage day one and day two operations of F5 in
  Azure
description: Use Terraform and Consul to manage day one and day two operations of
  F5 in Azure
icon: ""
tags: []
owner: hashicorp
developers:
- lance@hashicorp.com
- npearce@hashicorp.com
private: true
published: true
show_timer: true
challenges:
- slug: provision-azure-vnets
  id: y1cns7c1xooc
  type: challenge
  title: Provision Azure VNETs
  teaser: Deploy basic network infrastructure using Terraform
  assignment: |-
    In this assignment you will provision the VNets we will use in the following assignments. <br>

    Inspect and deploy the Terraform code.

    In the `Shell` tab run the following commands.
    ```
    terraform plan
    terraform apply -auto-approve
    ```

    Their CIDR blocks are listed below:
    ```
    hcs-vnet: 10.0.0.0/16
    shared-svcs-vnet: 10.2.0.0/16
    legacy-vnet: 10.3.0.0/16
    ```

    You will leverage these VNet in the next few assignments.
  notes:
  - type: text
    contents: |
      Setting up your environment... Your Azure account will be ready in ~5 minutes.
      Keep an eye on the bottom right corner to know when you can get started.
  tabs:
  - title: Cloud Consoles
    type: service
    hostname: workstation
    path: /
    port: 80
  - title: Shell
    type: terminal
    hostname: workstation
  - title: Text Editor
    type: code
    hostname: workstation
    path: /root/terraform/vnet
  - title: Current lab setup
    type: website
    url: https://htmlpreview.github.io/?https://raw.githubusercontent.com/hashicorp/field-workshops-consul/master/instruqt-tracks/f5-hashicorp-app-mod-tf-consul/assets/diagrams/provision-azure-vnets.html
  difficulty: basic
  timelimit: 3000
- slug: provision-core-services
  id: 8g5r3gchzqun
  type: challenge
  title: Provision Core Services
  teaser: Provision HCS using Terraform
  assignment: |-
    You will use Terraform to provision these services in the background while you set up Consul in the next few assignments. <br>

    In the `Shell` tab run the following commands.

    ```
    cd /root/terraform/hcs
    terraform init
    terraform plan
    terraform apply -auto-approve > /root/terraform/hcs/terraform.out &
    ```

    Montitor progress:
    ```
    tail -f /root/terraform/hcs/terraform.out
    ```
  notes:
  - type: text
    contents: |
      Terraform allows you to document, share, and deploy environments in one workflow by using Infrastructure as Code!
  tabs:
  - title: Cloud Consoles
    type: service
    hostname: workstation
    path: /
    port: 80
  - title: Shell
    type: terminal
    hostname: workstation
  - title: Vault Terraform Code
    type: code
    hostname: workstation
    path: /root/terraform/vault
  - title: HCS Terraform Code
    type: code
    hostname: workstation
    path: /root/terraform/hcs
  - title: Current lab setup
    type: website
    url: https://htmlpreview.github.io/?https://raw.githubusercontent.com/hashicorp/field-workshops-consul/master/instruqt-tracks/f5-hashicorp-app-mod-tf-consul/assets/diagrams/provision-core-services.html
  difficulty: basic
  timelimit: 3000
- slug: provision-f5
  id: fbyphtsxladi
  type: challenge
  title: Provision F5
  teaser: Provision an F5 BIG-IP VE using Terraform
  assignment: |-
    Now we will provision the F5 BIG-IP Virtual Edition using Terraform. <br>

    In the `Shell` tab run the following commands.
    ```
    terraform plan
    terraform apply -auto-approve > /root/terraform/bigip/terraform.out &
    ```

    This can take several minutes to complete, while you are waiting
    take the opportunity to review the `Terraform Code` tab to see the IaC definition.

    Once the apply is complete, you can Navigate to the BIG-IP at the IP address in the Terraform output.

    **NOTE:** you will need open the URL provided by the output in a separate tab.  If you are using chrome, you
    may be presented with a certificate error, to bypass this you can type "thisisunsafe" into the Chrome window.

    The HCS services may not be running quite yet, you can monitor their progress with the following commands.

    Monitor HCS provisioning
    ```
    cat /root/terraform/hcs/terraform.out
    ```

    Monitor F5 BIG-IP provisioning
    ```
    cat /root/terraform/bigip/terraform.out
    ```
  notes:
  - type: text
    contents: |
      In this exercise we will be provisioning an F5 BIG-IP Virtual Edition using Terraform.
  tabs:
  - title: Cloud Consoles
    type: service
    hostname: workstation
    path: /
    port: 80
  - title: Shell
    type: terminal
    hostname: workstation
  - title: Terraform Code
    type: code
    hostname: workstation
    path: /root/terraform/bigip
  - title: Current lab setup
    type: website
    url: https://htmlpreview.github.io/?https://raw.githubusercontent.com/hashicorp/field-workshops-consul/master/instruqt-tracks/f5-hashicorp-app-mod-tf-consul/assets/diagrams/provision-f5.html
  difficulty: basic
  timelimit: 3000
- slug: deploy-legacy-environments
  id: k0reagnnfzuc
  type: challenge
  title: Deploy Legacy environments
  teaser: Migrate an existing VM based application to the cloud.
  assignment: |2-

    In this assignment we will be deploying the current application into Azure based VM's. <br>

    As part of the cloud migration, the VM's will also be configured to run a Consul agent that registers these services with Consul.  This will make it easy to refactor the application, as the application is no longer dependent upon static IP addresses which are hardcoded into configuration and application code. <br>

    This also means that IP addresses no longer have to be known before provisioning can occur, thus, decoupling steps in the provisioning workflow.


    Review the code in the `Terraform Code` this defines the VMSS for the web and app tiers of the application.

    Begin provisioning the application in the background.

    ```
    terraform plan
    nohup terraform apply -auto-approve > deploy_app.log 2>&1 &
    ```

    By registering nodes and services in Consul other services can easily discover their status and location. <br>

    For example, it is no longer required to manually manage pool members on the F5 appliances. Instead, VIPs can be configured to populate backend pool members by monitoring services in Consul. Whenever the application scales up, down, fails a check, or moves the BIG-IP will automatically update it's configuration. <br>

    VIP deployment is also automated by way of an AS3 declaration which is deployed via Terraform. The AS3 declaration for the legacy application defines a VIP, a corresponding node pool which will be dynamically populated by Consul, and a WAF policy that helps protect the application from bad actors.

    Inspect the AS3 declaration.
    ```
    cd /root/terraform/legacy/as3
    cat templates/as3_declaration.json
    ```

    Provision the VIP using Terraform.
    ```
    cd /root/terraform/legacy/as3
    terraform plan
    terraform apply -auto-approve
    ```

    The application is now being migrated to the cloud!!! You can monitor the status of your application via Consul. <br>

    Once everything looks good you can visit the application in the `App` tab. You may need to hit the refresh button **within** that tab. <br>

    You will explore the environment in more detail in the next challange. <br>
  notes:
  - type: text
    contents: |
      For a lot of organizations digital transformation may start with a simple "lift and shift" to the cloud for existing workloads!
  tabs:
  - title: Shell
    type: terminal
    hostname: workstation
  - title: Current lab setup
    type: website
    url: https://htmlpreview.github.io/?https://raw.githubusercontent.com/hashicorp/field-workshops-consul/master/instruqt-tracks/f5-hashicorp-app-mod-tf-consul/assets/diagrams/final-architecture.html
  - title: Consul
    type: service
    hostname: workstation
    path: /
    port: 8500
  - title: App
    type: service
    hostname: workstation
    path: /ui
    port: 8080
  - title: Cloud Consoles
    type: service
    hostname: workstation
    path: /
    port: 80
  - title: Terraform Code
    type: code
    hostname: workstation
    path: /root/terraform/legacy
  - title: App Access Info
    type: code
    hostname: workstation
    path: /info.txt
  - title: Vault
    type: service
    hostname: workstation
    path: /
    port: 8200
  difficulty: basic
  timelimit: 3000
- slug: review-legacy-environment
  id: hbbtrye3yi1b
  type: challenge
  title: Review legacy environment
  teaser: Review the components of the legacy application
  assignment: |-
    The VM based application is now configured as part of a VM scale set on Azure.  One of the first challenges that comes up is that instances of the scale set will be provisioned with dynamic IP addresses. <br>

    This makes it difficult to maintain any configuration files which require hard coded IP addresses, luckily Consul can help solve this.

    Consul maintains a real-time catalog of all of the nodes and services in the environment.  This catalog can be queried using a UI, CLI, API, or simple DNS interface.

    Let's review the components of the application and see how Consul is leveraged in different ways.

    ** F5 LTM ** <br>

    **Remember you will to need to view this UI in a different browser tab**, for convenenience we have put all the required information in the `info.txt` file in the `App Access Info` tab <br>

    The VIP and pools are provisioned in the `Consul_SD` partition, make sure you select it from the drop down menu in the top right corner of the screen.

    You can view the VIP in the BIG-IP UI by naviagating to the `Local Traffic -> Virtual Servers`

    You can view the pool members navigating to `Local Traffic -> Pools`



    ** Web Tier ** <br>

    The VIP for the web tier of the application lives on the F5 BIG-IP virtual appliance. The pools servicing this VIP are dynamically populated by querying Consul for all instances of the service called `web` <br>

    The mapping between Consul and the pools was declared in the AS3 declaration of the VIP.

    Examine the AS3 declaration for the application.  You will see where the members are referencing a Consul API endpoint.

    From the `Shell` tab
    ```
    cat as3/templates/as3_declaration.json
    ```

    The AS3 definition also includes a WAF policy. You can review the configured policy by navigating to the `Security -> Application Security -> Security Policies` tab in the `Consul_SD` partition <br>

    The WAF policy contains a URL blocking strategy that prevents users from attempting to access sensitive portions of the application.

    ** Test WAF Policy **

    The sample WAF policy includes a rule that ensures that the `/admin` path of the application is not available externally.  You open a new tab using the URL of the application contained within the `App Access Info` tab.  The application should come up, add `/admin` to the URL in your browser. We can also test the WAF policy using curl in the local shell.

    Test a URL allowed by the WAF policy
    ```
    vip=$(terraform output -state /root/terraform/bigip/terraform.tfstate  app_url)
    curl $vip

    ```

    Test a URL blocked by the WAF policy
    ```
    vip=$(terraform output -state /root/terraform/bigip/terraform.tfstate  app_url)
    curl $vip/admin

    ```

    Next you can explore some of the service discovery capabilities of Consul.

    View the nodes and services via CLI

    ```
    consul members
    consul catalog services
    ```

    You can also retrieve information programatically via the API.  In this example you will be determining the IP address of the first web servers returned by the API. <br>

    ```
    web_server=$(curl -s $CONSUL_HTTP_ADDR/v1/catalog/service/web | jq -r '.[0].Address')
    echo $web_server
    ```

    ** NGiNX **

    Nginx is running on each of the web servers and is used to proxy and load balance requests to the app tier.

    Rather than managing the configuration files for the proxy manually, we'll instead rely on Consul and a library called [Consul Template](https://github.com/hashicorp/consul-template) <br>

    Consul Template is responsible for monitoring Consul for changes to the `app` service, and when changes are detected, render a new configuration file and restart NGiNX automatically.

    **Pro Tip:** Consul template can render any ASCII based configuration files you may need for other purposes, and fire a user defined handler after (re)rendering. <br>

    The next few steps will show how this is configured, by accessing the `$web_server` you discovered and stored previously through a bastion host that has also been configured. <br><br>

    1. Review the consul-template configuration
    ```
    ssh -q -A -J azure-user@$bastion_ip azure-user@$web_server \
      sudo cat /etc/consul-template/consul-template-config.hcl
    ```
    <br>

    2. Review the templated nginx configuration

    ```
    ssh -q -A -J azure-user@$bastion_ip azure-user@$web_server sudo cat /etc/nginx/conf.d/load-balancer.conf.ctmpl
    ```
    <br>
    3. Review the rendered configuration, and compare it to the information you've discovered via the other Consul interfaces.

    ```
    ssh -q -A -J azure-user@$bastion_ip azure-user@$web_server sudo cat /etc/nginx/conf.d/default.conf
    ```

    We are now able to connect things together using **Service Names** instead of IP addresses. In the next exercise we will scale the application and watch Consul take care of the rest! <br>
  notes:
  - type: text
    contents: |
      Now let's review the application environment we've deployed!
  tabs:
  - title: Cloud Consoles
    type: service
    hostname: workstation
    path: /
    port: 80
  - title: Consul
    type: service
    hostname: workstation
    path: /
    port: 8500
  - title: App Access Info
    type: code
    hostname: workstation
    path: /info.txt
  - title: Shell
    type: terminal
    hostname: workstation
  - title: App
    type: service
    hostname: workstation
    path: /ui
    port: 8080
  - title: Vault
    type: service
    hostname: workstation
    path: /
    port: 8200
  - title: Terraform Code
    type: code
    hostname: workstation
    path: /root/terraform/legacy
  - title: Current lab setup
    type: website
    url: https://htmlpreview.github.io/?https://raw.githubusercontent.com/hashicorp/field-workshops-consul/master/instruqt-tracks/f5-hashicorp-app-mod-tf-consul/assets/diagrams/final-architecture.html
  difficulty: basic
  timelimit: 3000
- slug: scale-the-application
  id: tjlwihpjo0s9
  type: challenge
  title: Scale the application
  teaser: Let Consul take care of routine adds/moves/changes of services instances.
  assignment: |-
    Now let's re-run the Terraform code for the legacy application, but pass in some new variables for the scale parameters.

    ```
    terraform apply -var app_count=3 -var web_count=3 -auto-approve
    ```

    After the Terraform run completes, you can monitor the status of your nodes and services using the Consul UI. Once all of the new instances are online and healthy, you can revisit some of the things we reviewed in the previous exercise.

    View the nodes and services via CLI

    ```
    consul members
    consul catalog services
    ```

    Review all of the web instances

    ```
    curl -s $CONSUL_HTTP_ADDR/v1/catalog/service/web | jq
    ```

    Review all of the app instances

    ```
    curl -s $CONSUL_HTTP_ADDR/v1/catalog/service/app | jq
    ```

    Review the updated nginx configuration on the web_server

    ```
    ssh -q -A -J azure-user@$bastion_ip azure-user@$web_server sudo cat /etc/nginx/conf.d/default.conf
    ```

    Review the VIP and pool configuration on LTM once again.

    The resources for this lab will self-destruct in 8 hours, but to save a little money, **please scale the application back down.**

    Re-run Terraform, and monitor the various integration points once again. We'll do so in the background so that you can move on whenever you're ready. <br>

    ```
    nohup terraform apply -var app_count=1 -var web_count=1 -auto-approve > /root/terraform/legacy/scaledown.out &
    ```

    **Some other things you can try:**

    1. Refresh the application page several times, and notice the load balancing occur.
    2. Explore the [Consul API](https://www.consul.io/api-docs/index) a bit more, Consul is a wonderful real-time source of truth for dynamic network environments.
    ```
    curl -s $CONSUL_HTTP_ADDR/v1/health/checks/web | jq
    curl -s $CONSUL_HTTP_ADDR/v1/health/checks/app | jq
    ```
    3. Consul can even estimate [round trip](https://www.consul.io/docs/internals/coordinates) times between nodes/datacenter. This is useful for finding the closest service instance, or datacenter for failover operations.
    ```
    consul rtt web-vm-000001 app-vm-000000
    ```
    **NOTE:** you may need to update the node names to match your environment

    Now that we are routing traffic based upon **service identity** we gain a lot of flexibility as more modern microservices architectures are adopted.
  notes:
  - type: text
    contents: |
      75% companies surveyed take Days or even Weeks to complete networking tasks.

      Organizations seeking to improve application delivery cycle are often blocked at the networking layer

      [source](https://zkresearch.com/research/2017-application-delivery-controller-study)
  tabs:
  - title: Cloud Consoles
    type: service
    hostname: workstation
    path: /
    port: 80
  - title: App
    type: service
    hostname: workstation
    path: /ui
    port: 8080
  - title: Vault
    type: service
    hostname: workstation
    path: /
    port: 8200
  - title: App Access Info
    type: code
    hostname: workstation
    path: /info.txt
  - title: Shell
    type: terminal
    hostname: workstation
  - title: Consul
    type: service
    hostname: workstation
    path: /
    port: 8500
  - title: Current lab setup
    type: website
    url: https://htmlpreview.github.io/?https://raw.githubusercontent.com/hashicorp/field-workshops-consul/master/instruqt-tracks/f5-hashicorp-app-mod-tf-consul/assets/diagrams/final-architecture.html
  - title: Terraform Code
    type: code
    hostname: workstation
    path: /root/terraform/legacy
  difficulty: basic
  timelimit: 3000
- slug: install-consul-terraform-sync
  id: 0szqwz2yuryf
  type: challenge
  title: Install Consul-Terraform-Sync
  teaser: Install Consul-Terraform-Sync and integrate w/ BIG-IP
  assignment: "Download the consul agent and the consul-terraform-sync binary\n\n```\ncurl
    -o http://\ncurl -o http://\nunzip    \nunzip    \n```\n\nCreate the configutation
    file:\n\n```\ncat <<EOF\n\nEOF\n```\nCongrats! All your base are belong to us."
  tabs:
  - title: Consul
    type: service
    hostname: workstation
    path: /
    port: 8500
  - title: Shell
    type: terminal
    hostname: workstation
  difficulty: basic
  timelimit: 3000
checksum: "8379239842886734802"
